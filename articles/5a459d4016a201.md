---
title: "Vercel AI SDK ã§ Ollama ã‚’ä½¿ã†æ–¹æ³•"
emoji: "ğŸ¦™"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [vercel, llm, ollama, llama, react]
published: true
---

# ã¯ã˜ã‚ã«

Vercel AI SDK (React ç­‰ã‹ã‚‰ LLM ã® API ã‚’ã„ã„æ„Ÿã˜ã« stream ã§å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã‚„ã¤) ã‹ã‚‰ Ollama ï¼ˆOSS ã® LLM ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ã‹ã™ã‚„ã¤ï¼‰ ã‚’å‘¼ã³å‡ºã™æ–¹æ³•ã‚’èª¿ã¹ã¾ã—ãŸã€‚

## å‚è€ƒ

https://zenn.dev/optimisuke/articles/c29fe9ef8cd28d

# èª²é¡Œ

Vercel AI SDK ã® ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ã€OpenAI ã‹ã‚‰ Ollama ã® langchain ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€ç½®ãæ›ãˆã¦å‹•ã‹ãã†ã¨ã—ãŸã‘ã©ã€ãªãœã‹ã†ã¾ãã„ã‹ãªã‹ã£ãŸã€‚

# è§£æ±ºæ–¹æ³•

ã“ã“ã®ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã«ã„ã‚ã‚“ãªè§£æ±ºæ–¹æ³•ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚ãã®ä¸­ã‹ã‚‰ã„ãã¤ã‹è©¦ã—ãŸã€‚

https://github.com/vercel/ai/discussions/539

## è§£æ±ºæ–¹æ³• 1 OpenAI Compatibility API ã‚’ä½¿ã†

OpenAI API ã¨åŒã˜ API ã§å‘¼ã³å‡ºã™æ–¹æ³•ã€‚å‘¼ã³å‡ºã›ã‚‹ãƒ¢ãƒ‡ãƒ«ã«åˆ¶ç´„ãŒã‚ã‚‹ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã® llava ã¯å‘¼ã³å‡ºã›ãªã„ã€‚
URL å¤‰ãˆã‚‹ãã‚‰ã„ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã€‚ã™ã‚“ãªã‚Šå‹•ã„ãŸã€‚
https://ollama.com/blog/openai-compatibility

## è§£æ±ºæ–¹æ³• 2 langchain ã® ChatOllama ã‚’ä½¿ã†

ã“ã®äººã®ã‚³ãƒ¼ãƒ‰ã‚’çœŸä¼¼ã—ãŸã€‚ã‚·ãƒ³ãƒ—ãƒ«ã ã—ã„ã„æ„Ÿã˜ã€‚
ã“ã‚Œã ã¨ã€ä¿®æ­£ã—ãŸã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã® llava ã‚‚å‹•ã„ãŸã€‚
https://github.com/brunnolou/next-ollama-app

## è§£æ±ºæ–¹æ³• 3 langchain ã® ChatOllama ã‚’ä½¿ã†ï¼ˆä¿®æ­£ç‰ˆï¼‰

æ¯”è¼ƒçš„æœ€è¿‘ã€langchain ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¸€éƒ¨ãŒã€`@langchain/core`ã¨`@langchain/community`ã«ã‚ã‹ã‚ŒãŸã€‚
ãã‚Œã«åˆã‚ã›ã‚‹ã¨è§£æ±ºæ–¹æ³• 2 ã¯ã“ã‚“ãªæ„Ÿã˜ã€‚

```ts:app/api/chat/route.ts
import { StreamingTextResponse, Message } from "ai";
import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { ChatOllama } from "@langchain/community/chat_models/ollama";
import { BytesOutputParser } from "@langchain/core/output_parsers";

export const runtime = "edge";

export async function POST(req: Request) {
  const { messages } = await req.json();

  const model = new ChatOllama({
    baseUrl: process.env.OLLAMA_BASE_URL,
    model: "mistral",
  });

  const parser = new BytesOutputParser();

  const stream = await model
    .pipe(parser)
    .stream(
      (messages as Message[]).map((m) =>
        m.role == "user"
          ? new HumanMessage(m.content)
          : new AIMessage(m.content)
      )
    );

  return new StreamingTextResponse(stream);
}
```

https://github.com/langchain-ai/langchainjs?tab=readme-ov-file#-what-is-langchain

## è§£æ±ºæ–¹æ³• 4 Vercel ã® ModelFusion ã‚’ä½¿ã†

ModelFusionï¼ˆAI ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ãŸã‚ã® TypeScript ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã‚’ä½¿ã†ã€‚
Vercel å¤§å¥½ããªã‚‰ã€ã“ã‚Œã‚‚è‰¯ã„ã‹ã‚‚ã€‚ãƒ¢ãƒ‡ãƒ«ã«åˆ¶ç´„ã‚ã‚Šãã†ã€‚

https://github.com/lgrammel/modelfusion-ollama-nextjs-starter

https://github.com/vercel/modelfusion

# ãŠã‚ã‚Šã«

ç„¡äº‹å‹•ã„ã¦ã‚ˆã‹ã£ãŸã€‚
