---
title: "OpenLLMetryã‚’ä½¿ã£ã¦OpenAIå‘¼ã³å‡ºã—ã‚’Trace/Metrics/Logsã§å¯è¦–åŒ–ã™ã‚‹ (Python + Grafana)"
emoji: "ğŸ”­"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["opentelemetry", "grafana", "python", "openai", "observability"]
published: true
---

# ã¯ã˜ã‚ã«

N ç•ªç…ã˜ã§ã¯ã‚ã‚Šã¾ã™ãŒã€OpenLLMetry ã‚’è©¦ã—ã¦ã¿ãŸã®ã§å…±æœ‰ã§ã™ã€‚
ãƒã‚¤ãƒ³ãƒˆã¯ Trace, Metrics, Log ã® 3 ã¤ã¨ã‚‚ç¢ºèªã—ãŸã¨ã“ã‚ã§ã™ã€‚

# OpenLLMetry ã£ã¦ä½•ï¼Ÿ

OpenLLMetry ã¯ã€LLM ã‚¢ãƒ—ãƒªã®å‹•ãã‚’ OpenTelemetry ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆTrace / Metrics / Logsï¼‰ã¨ã—ã¦è¦³æ¸¬ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®è¨ˆè£…ãƒ„ãƒ¼ãƒ«ç¾¤ã§ã™ã€‚æä¾›å…ƒã¯ Traceloop ã§ã€OpenAI / LangChain ãªã©ä¸»è¦ãª LLM ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå‘ã‘ã«ã€`@task` / `@workflow` ã¨ã„ã£ãŸã€Œå‡¦ç†ã®ã¾ã¨ã¾ã‚Šã€ã‚’è¡¨ç¾ã™ã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å«ã‚€ SDK ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

ã“ã®ãƒ¡ãƒ¢ã§ã¯ã€Python ã§ OpenAI å‘¼ã³å‡ºã—ã‚’å«ã‚€ã‚¸ãƒ§ãƒ–ã‚’ OpenTelemetry ã¨ã—ã¦åãå‡ºã—ã€Grafanaï¼ˆTempo/Prometheus/Loki ãªã©ï¼‰ã§ç¢ºèªã™ã‚‹ã¾ã§ã®æœ€çŸ­ãƒ«ãƒ¼ãƒˆã‚’ã¾ã¨ã‚ã¾ã™ã€‚

## å‚è€ƒ

### OpenLLMetry

https://github.com/traceloop/openllmetry
https://www.traceloop.com/docs/openllmetry/introduction

# ä½•ãŒå¬‰ã—ã„ï¼Ÿ

- **LLM API å‘¼ã³å‡ºã—ã‚’ã€Œã©ã®å‡¦ç†ã®ä¸­ã§ã€ã€Œã©ã‚Œãã‚‰ã„æ™‚é–“ãŒã‹ã‹ã£ãŸã‹ã€è¿½ãˆã‚‹**ï¼ˆTraceï¼‰
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å…¨ä½“ãƒ»ã‚¿ã‚¹ã‚¯ã”ã¨ã®åˆ†è§£**ãŒã§ãã‚‹ï¼ˆ`@workflow` / `@task`ï¼‰
- **æ—¢å­˜ã® `logging` ã‚’ã»ã¼ãã®ã¾ã¾** OpenTelemetry Logs ã¨ã—ã¦é›†ç´„ã§ãã‚‹ï¼ˆOpenTelemetry ã®æ©Ÿèƒ½ï¼‰
- å¯¾å¿œãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆä¾‹: OpenAIï¼‰ã«ã¤ã„ã¦ã¯ **å‘¼ã³å‡ºã—è‡ªä½“ã®è¨ˆè£…ã‚’ã‹ãªã‚Šè‡ªå‹•åŒ–**ã§ãã‚‹

æ³¨æ„: ã€Œå‡¦ç†ã®æ„å‘³ã¥ã‘ï¼ˆä¾‹: ã“ã‚Œã¯ `llm_job` ã®ä¸­ã® `openai_call` ã§ã‚ã‚‹ï¼‰ã€ã¯ã€åŸºæœ¬çš„ã«ã‚¢ãƒ—ãƒªå´ã§ `@task` / `@workflow` ãªã©ã‚’ä»˜ã‘ã¦è¡¨ç¾ã—ã¾ã™ã€‚

# äº‹å‰æº–å‚™

## åé›†å…ˆï¼ˆOTel Collector / Grafanaï¼‰

OTLPï¼ˆgRPCï¼‰ã§å—ã‘ã‚‰ã‚Œã‚‹ Collector ãŒç«‹ã£ã¦ã„ã‚Œã°ä½•ã§ã‚‚ OK ã§ã™ã€‚ã“ã“ã§ã¯ Grafana ã® LGTM ç³»ï¼ˆLoki/Grafana/Tempo/Mimir or Prometheusï¼‰ã‚’ `docker compose` ã§ç«‹ã¡ä¸Šã’ã‚‹æƒ³å®šã«ã—ã¾ã™ï¼ˆå¾Œè¿°ã®å‚è€ƒãƒªãƒ³ã‚¯ï¼‰ã€‚

# ã‚³ãƒ¼ãƒ‰

Trace / Metrics / Logs ã‚’å…¨éƒ¨é€ã‚‹æ§‹æˆã«ã—ã¦ã„ã¾ã™ã€‚
å†—é•·ãªéƒ¨åˆ†ã‚‚ã‚ã‚‹ã‹ã‚‚ã§ã™ã€‚

```python
import logging
import os
import sys

from openai import OpenAI
from opentelemetry.exporter.otlp.proto.grpc._log_exporter import OTLPLogExporter
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from traceloop.sdk import Traceloop
from traceloop.sdk.decorators import task, workflow
from traceloop.sdk.instruments import Instruments


def _require_env(name: str) -> str:
    value = os.getenv(name)
    if value:
        return value
    print(f"Missing required env var: {name}", file=sys.stderr)
    sys.exit(2)


def _normalize_otlp_grpc_endpoint(endpoint: str) -> str:
    if endpoint.startswith("http://"):
        return endpoint.removeprefix("http://")
    if endpoint.startswith("https://"):
        return endpoint.removeprefix("https://")
    return endpoint


def init_traceloop() -> None:
    service_name = os.getenv("OTEL_SERVICE_NAME", "llm-job")
    otlp_endpoint = _normalize_otlp_grpc_endpoint(
        os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT", "http://collector:4317")
    )
    deployment_env = os.getenv("DEPLOYMENT_ENVIRONMENT", "development")

    span_exporter = OTLPSpanExporter(endpoint=otlp_endpoint, insecure=True)
    metric_exporter = OTLPMetricExporter(endpoint=otlp_endpoint, insecure=True)
    log_exporter = OTLPLogExporter(endpoint=otlp_endpoint, insecure=True)

    Traceloop.init(
        app_name=service_name,
        exporter=span_exporter,
        metrics_exporter=metric_exporter,
        logging_exporter=log_exporter,
        # job ãªã®ã§çŸ­æ™‚é–“ã§çµ‚äº†ã™ã‚‹ã€‚ãƒãƒƒãƒã ã¨çµ‚äº†æ™‚ã«é€ä¿¡ã—ãã‚Œãªã„ã“ã¨ãŒã‚ã‚‹ãŸã‚å³æ™‚é€ä¿¡ã«å¯„ã›ã‚‹ã€‚
        disable_batch=True,
        # Collector/LGTMå´ã§æ¢ã—ã‚„ã™ã„ã‚ˆã†ã«æœ€ä½é™ã ã‘ä»˜ä¸
        resource_attributes={
            "service.name": service_name,
            "deployment.environment": deployment_env,
        },
        instruments={Instruments.OPENAI},
    )


@task(name="openai_call")
def call_openai(model: str, prompt: str) -> str:
    client = OpenAI(api_key=_require_env("OPENAI_API_KEY"))
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
    )
    return resp.choices[0].message.content or ""


@workflow(name="llm_job")
def run_workflow(model: str, prompt: str) -> str:
    text = call_openai(model=model, prompt=prompt)
    return text


def main() -> int:
    init_traceloop()

    logging.basicConfig(level=logging.INFO)

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    prompt = os.getenv("OPENAI_PROMPT", "ä¿³å¥ã‚’è© ã‚“ã§ OpenTelemetryã«ã¤ã„ã¦")

    logger = logging.getLogger("llm-job")
    logger.info("Starting LLM job", extra={"openai.model": model})

    text = run_workflow(model=model, prompt=prompt)
    logger.info("LLM job completed", extra={"output.preview": text[:200]})
    print(text)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
```

ä»¥ä¸‹ã«å®Œå…¨ç‰ˆã‚’ç½®ã„ã¦ã¾ã™ã€‚
https://github.com/optimisuke/hello-otel/tree/main/llm-job

# å®Ÿè¡Œæ–¹æ³•

ä¾‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã« Collector ãŒã„ã¦ `localhost:4317` ã§ OTLP gRPC ã‚’å—ã‘ã‚‹å ´åˆï¼‰:

```bash
export OPENAI_API_KEY='...'
export OTEL_SERVICE_NAME='llm-job'
export DEPLOYMENT_ENVIRONMENT='development'
export OTEL_EXPORTER_OTLP_ENDPOINT='http://localhost:4317'

export OPENAI_MODEL='gpt-4o-mini'
export OPENAI_PROMPT='ä¿³å¥ã‚’è© ã‚“ã§ OpenTelemetryã«ã¤ã„ã¦'

python job.py
```

ãƒã‚¤ãƒ³ãƒˆ:

- `OTEL_EXPORTER_OTLP_ENDPOINT` ã‚’ `http://...` ã§æ¸¡ã—ã¦ã‚‚ã€ã‚³ãƒ¼ãƒ‰å´ã§ gRPC exporter ãŒæœŸå¾…ã™ã‚‹ `host:port` å½¢å¼ã«å¯„ã›ã¦ã„ã¾ã™ã€‚
- `logger.info(..., extra={...})` ã® `extra` ã¯ãƒ­ã‚°ã®å±æ€§ï¼ˆstructured fieldsï¼‰ã¨ã—ã¦è¼‰ã›ã‚‰ã‚Œã‚‹ã®ã§ã€å¾Œã§çµã‚Šè¾¼ã¿ã«ä½¿ãˆã¾ã™ã€‚

# å‚è€ƒ

## workflow/ task

workflow ã®ä¸­ã« taskã€ãã®ä¸­ã« chat ãŒå…¥ã£ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚

![](https://mintcdn.com/enrolla/GspX1ocwd1gETLy0/img/workflow-dark.png?w=1100&fit=max&auto=format&n=GspX1ocwd1gETLy0&q=85&s=ba9206af514f391cc75488c79367b1c9)

https://www.traceloop.com/docs/openllmetry/tracing/annotations

# ä½•ãŒå–ã‚ŒãŸã‹

ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã§ãã¾ã—ãŸã€‚

## traces

![](/images/2025-12-18-16-22-16.png)

## metrics

![](/images/2025-12-18-16-22-28.png)

## logs

![](/images/2025-12-18-16-22-46.png)

# Grafanaï¼ˆdocker compose ã®æº–å‚™ï¼‰

æ‰‹å…ƒã§ LGTM ã‚’ç«‹ã¦ã‚‹æ‰‹é †ã¯ä»¥ä¸‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
ã“ã®è¨˜äº‹ã§ã¯è©³ç´°ã¯å‰²æ„›ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚

https://zenn.dev/cepe_jp/articles/c07d75daba4e35
https://github.com/optimisuke/hello-otel

# ãŠã‚ã‚Šã«

æœŸå¾…é€šã‚Šå‹•ã„ã¦ã‚ˆã‹ã£ãŸã§ã™ã€‚ç¾åœ¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„çµæœã‚‚æ®‹ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦ç„¡åŠ¹ã«ã—ãŸã»ã†ãŒè‰¯ã„ã¨æ€ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ OTel Collector ã§ãƒã‚¹ã‚¯å‡¦ç†ã‚’å®Ÿæ–½ã—ãŸã‚Šã€ãƒãƒƒã‚·ãƒ¥åŒ–ã™ã‚‹ã¨ã€ã‚ˆã‚Šã‚»ã‚­ãƒ¥ã‚¢ã«ãªã‚‹ã¨æ€ã„ã¾ã™ã€‚
