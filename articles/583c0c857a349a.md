---
title: "IBMのWatson Speech to TextをTypeScriptで呼び出してみた"
emoji: "🎤"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [ibm, typescript]
published: true
---

# はじめに
IBMのWatson Speech to TextをTypeScriptで呼び出してみた。日本語情報少なめやったので記録。
調べ物したことを最初に書いて、IBM Cloud、コード、実行についてそれぞれ説明して、最後にまとめる。

# 調べ物
## サービスの概要
[ここ](https://www.ibm.com/cloud/watson-speech-to-text)に書かれてる。

## APIの仕様
[ここ](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-gettingStarted#getting-started-tutorial)。`curl`で呼ぶ方法も書かれてるので、まずここから試すのが良さげ。普通に使うなら、API一回叩くだけで、transcribeしてくれる。[Amazon Transcribe](https://aws.amazon.com/jp/transcribe/)だと、S3に保存してtranscribeする感じやから、シンプルと言えばシンプルな気がする。設計の違いを垣間見れて面白い。良し悪しあるんやろなー。

## SDKの仕様
[ここ](https://cloud.ibm.com/apidocs/speech-to-text?code=node#recognize)。言語ごとにExampleも載ってる。ありがたや。

## Node.jsのSDK
[ここ](https://github.com/watson-developer-cloud/node-sdk)。Watson APIs全部入りなので、Speech to Textのところ探して使う必要ある。

## 日本語の記事
あまりない。[Speech To Text で音声認識してみた - Qiita](https://qiita.com/Haruka-Ogawa/items/a022cee97a7455e1e9eb) ってのがあったけど、古いSDKやった。

## サンプルコード
まずは公式の[ここ](https://github.com/watson-developer-cloud/node-sdk#speech-to-text)と[ここ](https://cloud.ibm.com/apidocs/speech-to-text?code=node#recognize)をコピペするところから始めるのが良さげ。試してないけど、websocket使ってストリーミング処理もできるみたい。websocketわからん。

# 前提
IBM Cloudのアカウント持ってる。

# IBM Cloudでリソースの登録とAPI Keyの取得。
カタログから、Speech to Textを探す。
![](/images/583c0c857a349a/catalog-IBM-Cloud.png)

ロケーション等を選択してリソースを作成する。
![](/images/583c0c857a349a/Speech-to-Text-IBM-Cloud.png)

リソース・リストから作成したSpeech to Textリソースを選ぶ
![](/images/583c0c857a349a/IBM-Cloud.png)
![](/images/583c0c857a349a/resource-IBM-Cloud.png)

API KeyとURLを取得する。
![](/images/583c0c857a349a/IBM-Watson-service.png)

# Node.js x TypeScriptの設定

ここらのコマンドを打って、環境を作る。デフォルトで動く。
nodeのバージョンに合わせて、`@types/node`をインストールしてる。

```
npm init
node -v
npm install -D typescript @types/node@14
npx tsc --version
npx tsc --init
npm install -D ibm-watson@^7.0.0 
npm install -D ts-node
```


# コード

1. [ここ](https://cloud.ibm.com/apidocs/speech-to-text?code=node#recognize)のコードをコピペして、
2. なんとなく、`require`しているところを`import`にして、
3. 不要なパラメータ削って、
4. apikeyとserviceUrlを環境変数から取ってきただけ。
   

apikeyとserviceUrlは、上記手順でIBM Cloudから取得したものを使用。
TypeScript的にはlinterに怒られてないからこれで大丈夫そう。

```typescript
import fs from 'fs';
import SpeechToTextV1 from 'ibm-watson/speech-to-text/v1';
import { IamAuthenticator } from 'ibm-watson/auth';

const speechToText = new SpeechToTextV1({
    authenticator: new IamAuthenticator({
        apikey: process.env.SPEECH_TO_TEXT_APIKEY || '',
    }),
    serviceUrl: process.env.SPEECH_TO_TEXT_SERVICE_URL || '',
});

const recognizeParams = {
    audio: fs.createReadStream('audio-file.flac'),
    contentType: 'audio/flac',
};

speechToText.recognize(recognizeParams)
    .then(speechRecognitionResults => {
        console.log(JSON.stringify(speechRecognitionResults, null, 2));
    })
    .catch(err => {
        console.log('error:', err);
    });
```

# 実行
実行するときは、こんな感じ。`.bashrc`とか`.zshrc`とかで環境変数に登録してたら、`npx ts-node index.ts`でOK。

```
SPEECH_TO_TEXT_APIKEY=APIKEY SPEECH_TO_TEXT_SERVICE_URL=https://APIURL npx ts-node index.ts
```

結果はこんな感じのjsonで返ってくる。`result.results[0].alternatives[0].transcript`に文字起こし結果が入ってる。いい感じ。

```json
{
  "status": 200,
  "statusText": "OK",
  "headers": {
    "いろいろ": "省略"
  },
  "result": {
    "result_index": 0,
    "results": [
      {
        "final": true,
        "alternatives": [
          {
            "transcript": "several tornadoes touched down as a line of severe thunderstorms swept through Colorado on Sunday ",
            "confidence": 0.94
          }
        ]
      }
    ]
  }
}
```

# おわりに
もうちょい、迷いながら試してたけど、振り返って整理してみたら、公式サイトの情報見たら一発な感じやった。まじめに、公式サイト見ようってことか。。。
